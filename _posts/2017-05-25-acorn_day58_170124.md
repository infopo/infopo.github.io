---
layout: post
title: Hive, Sqoop - 17/01/24
category: acorn수업
---

## 증권데이터문제
NASDAQ_daily_prices_A_sample.csv, NASDAQ_dividends_A.csv 다운로드  

> [daily]  
field명  
exchange, stock_symbol, date,  
stock_price_open, stock_price_high, stock_price_low, stock_price_close,  
stock_volume, stock_price_adj_close  


> [dividends]  
field명  
exchange, stock_symbol, date, dividends  


1. NASDAQ daily data set을 위한 external table을 생성하시오.  
    ```
    hive > CREATE EXTERNAL TABLE daily_ex
      (exchange_1 STRING, stock_symbol STRING, date_1 STRING, stock_price_open FLOAT, 
       stock_price_high FLOAT, stock_price_low FLOAT, stock_price_close FLOAT, 
       stock_volume BIGINT, stock_price_adj_close FLOAT) 
      ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' 
      STORED AS TEXTFILE LOCATION '/user/hadoop/daily_ex';

    hive > LOAD DATA LOCAL INPATH '/home/hadoop/practice3_hive_test/NASDAQ_daily_prices_A_sample.csv' 
      OVERWRITE INTO TABLE daily_ex;
    ```


2. NASDAQ dividends data set(배당금)을 위한 external table을 생성하시오.
        ```
        hive > CREATE EXTERNAL TABLE dividends_ex
        (exchange_2 STRING, stock_symbol STRING, date_2 STRING, dividends FLOAT) 
        ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' 
        STORED AS TEXTFILE LOCATION '/user/hadoop/dividends_ex';

        hive > LOAD DATA LOCAL INPATH '/home/hadoop/practice3_hive_test/NASDAQ_dividends_A.csv' 
        OVERWRITE INTO TABLE dividends_ex;
        ```


3. 종가가 5$이상인 종목의 총거래량에 대한 값을 출력하시오.
      ```
      hive > select stock_price_close, sum(stock_volume) 
        from daily_ex 
        where stock_price_close > 5.0;

      hive > select stock_symbol, sum(stock_volume) 
        from daily_ex 
        where stock_price_close >5.0 
        group by stock_symbol;
      ```


4. 각 종목별 역대 최고가를 출력하시오.
      ```
      hive > select stock_symbol, MAX(stock_price_high) 
        from daily_ex 
        GROUP BY stock_symbol;
      ```


5. 역대 종목별 최고가 배당에 대하여 출력하시오.
      ```
      hive > SELECT stock_symbol, MAX(dividends) 
        FROM dividends_ex 
        GROUP BY stock_symbol;
      ```


6. 최고가와 최고배당이 존재한다면 최고가와 최고배당을 출력하시오.
      ```
      hive > select A.stock_symbol, MAX(A.stock_price_high), MAX(B.dividends) 
        from daily_ex A JOIN dividends_ex B on (A.stock_symbol=B.stock_symbol) 
        group by A.stock_symbol;
      ```


7. 최고가와 최고배당을 출력하시오. 만약 그 중 하나가 존재하지 않는다면 null로 두시오(즉, outer join)
      ```
      hive > select A.stock_symbol, MAX(A.stock_price_high), MAX(B.dividends) 
        FROM daily_ex A LEFT OUTER JOIN dividends_ex B on (A.stock_symbol=B.stock_symbol) 
        group by A.stock_symbol;

      hive > select B.stock_symbol, MAX(A.stock_price_high), MAX(B.dividends) 
        FROM dividends_ex B LEFT OUTER JOIN daily_ex A on (A.stock_symbol=B.stock_symbol) 
        group by B.stock_symbol;
      ```

---

## SQOOP 설치

```
$ pwd
/home/hadoop/

$ wget http://apache.mirror.cdnetworks.com/sqoop/1.4.6/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz
$ tar -vxzf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz

$ mkdir sqoop
///링크로 생성할폴더는 따로 mkdir로 만들지 않는다
$ln -s sqoop-1.4.6.bin__hadoop-2.0.4-alpha sqoop

$ cp /usr/share/java/mysql-connector-java.jar /home/hadoop/sqoop/lib

$ cd sqoop/conf
$ cp sqoop-site-template.xml sqoop-site.xml
$ cp sqoop-env-template.sh sqoop-env.sh

$ vi sqoop-env.sh   ///github
$ vi ~/.bashrc    ///github
$ source ~/.bashrc
```

```
///메일에서 weblog_entries.txt를 다운로드

///jw사용자로 터미널 접속 -> root 사용자로 이동
$ sudo su
# mkdir /var/lib/mysql/logs -p
# mv /home/jw/Downloads/weblog_entries.txt /var/lib/mysql/logs
# chmod 777 /var/lib/mysql/logs/weblog_entries.txt
# chown -R mysql:mysql /var/lib/mysql/logs/

///root 사용자에서 할 것
$ mysql -u root -p
mysql> show databases
mysql> use logs

mysql> create table weblogs(md5 varchar(32), url varchar(64), request_date DATE, request_time TIME, ip varchar(15)) engine=InnoDB;

mysql> create table weblogs_from_hdfs(md5 varchar(32), url varchar(64), request_date DATE, request_time TIME, ip varchar(15)) engine=InnoDB;

mysql> LOAD DATA LOCAL INFILE '/var/lib/mysql/logs/weblog_entries.txt' INTO TABLE weblogs FIELDS TERMINATED BY '      ' LINES TERMINATED BY '\r\n';

mysql> LOAD DATA LOCAL INFILE '/var/lib/mysql/logs/weblog_entries.txt' INTO TABLE weblogs FIELDS TERMINATED BY '\t' LINES TERMINATED BY '\r\n';
LOAD DATA LOCAL INFILE '/logs/weblog_entries.txt' INTO TABLE weblogs FIELDS TERMINATED BY '\t' LINES TERMINATED BY '\r\n';
```
```
$ sudo cp /usr/share/java/mysql-connector-java.jar $SQOOP_HOME/lib
$ sqoop import -m 1 --connect jdbc:mysql://localhost/logs --username root --password 123 --table weblogs --target-dir /data/weblogs/import

///-m 1 ===> mapreduce할 개수 (container?)
/// --connect jdbc:mysql://localhost/logs ===> logs는 데이터베이스 이름
/// --table weblogs ===? 테이블이름은 weblogs
/// --target-dir /data/weblogs/import ===> hdfs에 올라가는 위치
$ sqoop import -m 1 --driver com.mysql.jdbc.Driver --connect jdbc:mysql://localhost/logs --username root --password 123 --table weblogs --target-dir /data/weblogs/import

$ sqoop export -m 1 --driver com.mysql.jdbc.Driver --connect jdbc:mysql://localhost/logs --username root --password 123 --table weblogs_from_hdfs --export-dir /data/weblogs/import/part-m-00000 --input-fields-terminated-by ',  ' --mysql-delimiters
```
