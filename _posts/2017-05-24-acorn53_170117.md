---
layout: post
title: Hadoop - 17/01/17
category: acorn수업
---

## Hadoop 설치2

교재 p.450  

```
$ sudo vi /etc/hosts
ip 주소 추가

$ sudo hostname hadoopsvr   ///hostname 변경

$ cd /home/hadoop/hadoop/etc/hadoop/
$ sudo vi core-site.xml   ///ip주소 추가

$ stop-all.sh

$ wget http://apache.mirror.cdnetworks.com/hadoop/common/hadoop-2.7.2/hadoop-2.7.2-src.tar.gz
jw 사용자(기존 사용자)로 이동 후
$ sudo apt-get install cmake  (사용자 jw로 이동 후 할 것)
$ gcc -v
$ sudo apt-get install gcc-c++     //centos
$ sudo apt-get install openssl-devel     //centos

$ sudo apt-get install g++    ///Ubuntu
$ sudo apt-get install libssl-dev   ///Ubuntu
$ sudo apt-get install zlib1g-dev   ///Ubuntu

하둡 유저로 복귀
$ cd hadoop-2.7.2-src/

$ mvn package -Pdist,native -DskipTests -Dtar -Dmaven.javadoc.skip=true

$ cd ~/hadoop-2.7.2-src/hadoop-dist/target/hadoop-2.7.2/lib/native
$ ls -al       (파일이 총 8개이면 정상)
$ cp ~/hadoop-2.7.2-src/hadoop-dist/target/hadoop-2.7.2/lib/native/* ~/hadoop/lib/native

터미널에서 방화벽 컨트롤하기
$ firewall-cmd --permanent --zone=public --add-port=50070/tcp
$ firewall-cmd --permanent --zone=public --add-port=8088/tcp
$ systemctl restart firewalld
```

---

## Hadoop 예제1
```
$ start-dfs.sh
$ start-yarn.sh
크롬에서 입력 &rarr; 192.168.1.68:50070 (localhost가 아니고 자기의 ip주소로 들어갈 것)
$ hdfs dfs -mkdir /test    (하둡경로 아무데서나 해도 상관없다)
$ hdfs dfs -ls /           (/test 폴더가 생긴 것을 확인할 수 있다)

hadoop@hadoopsvr ~/hadoop $ pwd
/home/hadoop/hadoop
$ hdfs dfs -copyFromLocal LICENSE.txt /test
$ hdfs dfs -copyFromLocal README.txt.txt /test
$ hdfs dfs -ls /test
$ hdfs dfs -put NOTICE.txt /test
$ hdfs dfs -cat /test/NOTICE.txt
$ yarn jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /test/README.txt /outp1
    ---------
    17/01/17 11:49:49 INFO client.RMProxy: Connecting to ResourceManager at hadoopsvr/192.168.1.68:8032
    17/01/17 11:49:50 INFO input.FileInputFormat: Total input paths to process : 1
    17/01/17 11:49:50 INFO mapreduce.JobSubmitter: number of splits:1
    17/01/17 11:49:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1484621374530_0001
    17/01/17 11:49:51 INFO impl.YarnClientImpl: Submitted application application_1484621374530_0001
    17/01/17 11:49:51 INFO mapreduce.Job: The url to track the job: http://hadoopsvr:8088/proxy/application_1484621374530_0001/
    17/01/17 11:49:51 INFO mapreduce.Job: Running job: job_1484621374530_0001
    17/01/17 11:50:10 INFO mapreduce.Job: Job job_1484621374530_0001 running in uber mode : false
    17/01/17 11:50:10 INFO mapreduce.Job: map 0% reduce 0%
    17/01/17 11:50:23 INFO mapreduce.Job: map 100% reduce 0%
    17/01/17 11:50:30 INFO mapreduce.Job: map 100% reduce 100%
    17/01/17 11:50:31 INFO mapreduce.Job: Job job_1484621374530_0001 completed successfully
    17/01/17 11:50:31 INFO mapreduce.Job: Counters: 49
    ---------
    
$ hdfs dfs -ls /outp1
$ hdfs dfs -cat /outp1/part-r-00000
$ hdfs dfs -copyToLocal /outp1/part-r-00000 ~/
$ cd ~
$ vi part-r-00000
```

## Hadoop 예제2

- [MapReduce Tutorial](https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html){:target="_blank}

- [MapReduce - Combiners](https://www.tutorialspoint.com/map_reduce/map_reduce_combiners.htm){:target="_blank}

- [MapReduce model](https://www.cs.helsinki.fi/u/jilu/paper/course06.pdf){:target="_blank}

- [MapReduce 프로그래밍 IT/빅데이터(bigData)](http://micropai.tistory.com/1){:target="_blank}

[hadoop-core-1.2.1.jar 다운](http://repo1.maven.org/maven2/org/apache/hadoop/hadoop-core/1.2.1/){:target="_blank"}

```
jw@jw-Lenovo $ sudo chmod 777 hadoop-core-1.2.1.jar
$ mv hadoop-core-1.2.1.jar /home/hadoop
$ su hadoop
$ pwd
/home/hadoop
$ mkdir hadoop_test
$ mv hadoop-core-1.2.1.jar hadoop_test
$ cd hadoop_test
$ mkdir mapreduce_test
$ cd mapreduce_test
$ vi WordCount.java   ///github

$ pwd
/home/hadoop/hadoop_test/mapreduce_test

$ mkdir test
$ javac -cp ../hadoop-core.1.2.1.jar -d test/ WordCount.java

$ jar -cvf wordcount.jar -C test/ .

$ yarn jar wordcount.jar WordCount /test/README.txt /outp3
```

---

## Hadoop 예제3

```
$ pwd
/home/hadoop/hadoop_test
$ mkdir hdfs_test
$ cd hdfs_test
$ vi SingleFileWriteRead.java     ///(교재 p98), github

$ mkdir test
$ javac -cp ../hadoop-core-1.2.1.jar -d test SingleFileWriteRead.java -encoding utf8
$ jar -cvf maketohdfs.jar -C test/ .
$ yarn jar maketohdfs.jar hadoop.hdfs.SingleFileWriteRead maketest.txt i,love,korea

///inputString: i,love,korea
///maketest.txt에 대한 경로를 안 잡아주면 /user/hadoop에 파일이 생성된다

$ hdfs dfs -cat /user/hadoop/maketest.txt

$ hdfs dfs -rm /user/hadoop/maketest.txt
$ rm -rf test maketohdfs.jar

///FileSystem.class에 관한 doc
hadoop.apache.org/docs/r2.6.1/api/org/apache/hadoop/fs/FileSystem.html
///create(org.apache.hadoop.fs.Path)
```

---

## 항공데이터 다운로드

[Airline on-time performance](stat-computing.org/dataexpo/2009/the-data.html){:target="_blank"}

```
$ pwd
/home/hadoop/hadoop_test/
$ mkdir dataexpo
$ cd dataexpo
$ vi download.bash     ///.sh로는 우분투에서 인식안됨(centos는 됨)  ///github
$ chmod 755 download.bash
$ sudo bash download.bash
```
